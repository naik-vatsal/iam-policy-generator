{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "",
   "metadata": {},
   "source": [
    "# üöÄ AWS IAM Policy Generator ‚Äî Model Training & Evaluation\n",
    "**Project**: Fine-tuning Mistral-7B to convert natural language ‚Üí valid AWS IAM JSON policies  \n",
    "**Author**: Vatsal Naik | Northeastern University\n",
    "## This notebook covers:\n",
    "1. **Model Setup**: Mistral-7B-v0.3 with QLoRA (4-bit quantization)\n",
    "2. **Training**: 4 hyperparameter configurations with early stopping\n",
    "3. **Baseline Comparison**: Zero-shot vs Few-shot vs Fine-tuned\n",
    "4. **Evaluation**: JSON validity, schema compliance, service accuracy\n",
    "5. **Error Analysis**: Failure categorization, patterns by complexity\n",
    "6. **Inference Pipeline**: Gradio demo application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9c450",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "**Hardware**: NVIDIA A100-SXM4 80GB GPU\n",
    "\n",
    "**CUDA**: 12.1\n",
    "\n",
    "**Key Libraries**: transformers, peft (LoRA), bitsandbytes (4-bit quantization), trl (SFTTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b410f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft accelerate bitsandbytes sentencepiece protobuf trl scikit-learn matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee538518-3b40-4f60-835f-9851d3289867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n",
      "VRAM: 42 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.0f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a20ff",
   "metadata": {},
   "source": [
    "## 2. Authentication & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b829fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import loginimport os# Login using token stored in environment variable# Set via: export HF_TOKEN=hf_xxxxx before launching Jupyterlogin(token=os.environ.get(\"HF_TOKEN\", \"SET_YOUR_TOKEN\"))os.environ[\"WANDB_DISABLED\"] = \"true\"print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd80b2",
   "metadata": {},
   "source": [
    "## 3. Load DatasetLoading the preprocessed dataset created in `01_Dataset_Preparation.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbb08da-7a2e-478b-a162-c52ec8601911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'id', 'complexity', 'services', 'source'],\n",
      "        num_rows: 1189\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'id', 'complexity', 'services', 'source'],\n",
      "        num_rows: 148\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'id', 'complexity', 'services', 'source'],\n",
      "        num_rows: 151\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample:\n",
      "### Instruction:\n",
      "Provide an IAM policy for ROSA Cloud Network Config Operator Policy\n",
      "\n",
      "### Response:\n",
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"DescribeNetworkResources\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"ec2:DescribeInstances\",\n",
      "        \"ec2:DescribeInstanceSt...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "# Load the JSONL files you created\n",
    "dataset = load_dataset(\"json\", data_files={\n",
    "    \"train\": \"iam-finetuning/dataset/processed/train.jsonl\",\n",
    "    \"validation\": \"iam-finetuning/dataset/processed/val.jsonl\",\n",
    "    \"test\": \"iam-finetuning/dataset/processed/test.jsonl\",\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "print(f\"\\nSample:\\n{dataset['train'][0]['text'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfafa0d",
   "metadata": {},
   "source": [
    "## 4. Tokenizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ab02fa-6f06-42c9-8746-7612369e5f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample token count: 294\n",
      "Vocab size: 32768\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Test tokenization\n",
    "sample = dataset[\"train\"][0][\"text\"]\n",
    "tokens = tokenizer(sample, truncation=True, max_length=1024)\n",
    "print(f\"Sample token count: {len(tokens['input_ids'])}\")\n",
    "print(f\"Vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b20aa",
   "metadata": {},
   "source": [
    "## 5. Model Loading with QLoRAWe use **4-bit NF4 quantization** (QLoRA) to reduce the 7B parameter model from ~14GB to ~4GB VRAM, enabling efficient fine-tuning on a single GPU.\n",
    "\n",
    "|Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Base model | Mistral-7B-v0.3 |\n",
    "| Quantization | 4-bit NF4 |\n",
    "| Compute dtype | bfloat16 |\n",
    "| Double quantization | Enabled |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8206649-93f8-4d45-8764-40f7781eee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb2d5f8a6b84579a718758995edbac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! GPU memory used: 4.1 GB\n",
      "Model parameters: 7248M\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Check memory usage\n",
    "allocated = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"Model loaded! GPU memory used: {allocated:.1f} GB\")\n",
    "print(f\"Model parameters: {model.num_parameters() / 1e6:.0f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37f4d0",
   "metadata": {},
   "source": [
    "## 6. LoRA Adapter ConfigurationLow-Rank Adaptation (LoRA) trains only a small set of adapter weights (~0.6% of total parameters), making fine-tuning dramatically faster and more memory-efficient.\n",
    "\n",
    "|Parameter | Config A (Best) |\n",
    "|-----------|----------------|\n",
    "| Rank (r) | 16 |\n",
    "| Alpha | 32 |\n",
    "| Target modules | q, k, v, o, gate, up, down projections |\n",
    "| Dropout | 0.05 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37131902-3b51-4db3-a62f-576d45407a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 7,289,966,592 || trainable%: 0.5754\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA Config ‚Äî this is hyperparameter config A (balanced)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "# Should print something like: trainable params: 41M || all params: 7,283M || trainable%: 0.56%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370cebd6",
   "metadata": {},
   "source": [
    "## 7. Training### Config A: Balanced (LR=2e-4, r=16, Œ±=32, 3 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245f0b66-8b9f-4bb8-9cbb-3d740d44a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trl version: 0.27.2\n",
      "Training config ready!\n",
      "Effective batch size: 16\n",
      "Epochs: 3\n",
      "Learning rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Check what version of trl we have\n",
    "import trl\n",
    "print(f\"trl version: {trl.__version__}\")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./results/config_a\",\n",
    "    \n",
    "    # Training params\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    # Learning rate\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Eval\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    \n",
    "    # Saving\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    \n",
    "    # Performance\n",
    "    bf16=True,\n",
    "    max_length=1024,  # changed from max_seq_length\n",
    "    \n",
    "    # Misc\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Training config ready!\")\n",
    "print(f\"Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06a05df4-55d6-42ad-afb9-3f8cfb926990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1c164dfcc24a3e8062be2f0c76c7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/148 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9579c623f4d4458c80bdaeaaeb747d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/148 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1189\n",
      "Validation samples: 148\n",
      "Steps per epoch: 74\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [225/225 24:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.341420</td>\n",
       "      <td>0.349021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>0.321393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.214992</td>\n",
       "      <td>0.301875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.146991</td>\n",
       "      <td>0.315044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Train loss: 0.2506\n",
      "Training runtime: 1489 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(dataset['train'])}\")\n",
    "print(f\"Validation samples: {len(dataset['validation'])}\")\n",
    "print(f\"Steps per epoch: {len(dataset['train']) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)}\")\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Train loss: {train_result.metrics['train_loss']:.4f}\")\n",
    "print(f\"Training runtime: {train_result.metrics['train_runtime']:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b17465c-264c-419d-8450-e62a93fd8769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config A Results:\n",
      "  Final train loss: 0.1522\n",
      "  Best eval loss: 0.3019\n",
      "  Training steps: 220\n",
      "\n",
      "Logs saved!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save metrics\n",
    "log_history = trainer.state.log_history\n",
    "with open(\"results/config_a/training_logs.json\", \"w\") as f:\n",
    "    json.dump(log_history, f, indent=2)\n",
    "\n",
    "# Extract and display key metrics\n",
    "train_losses = [(l[\"step\"], l[\"loss\"]) for l in log_history if \"loss\" in l and \"eval_loss\" not in l]\n",
    "eval_losses = [(l[\"step\"], l[\"eval_loss\"]) for l in log_history if \"eval_loss\" in l]\n",
    "\n",
    "print(\"Config A Results:\")\n",
    "print(f\"  Final train loss: {train_losses[-1][1]:.4f}\")\n",
    "print(f\"  Best eval loss: {min(l[1] for l in eval_losses):.4f}\")\n",
    "print(f\"  Training steps: {train_losses[-1][0]}\")\n",
    "\n",
    "# Save these for later comparison\n",
    "config_a_results = {\n",
    "    \"config\": \"A - balanced\",\n",
    "    \"lr\": 2e-4,\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": \"4 x 4 = 16\",\n",
    "    \"final_train_loss\": train_losses[-1][1],\n",
    "    \"best_eval_loss\": min(l[1] for l in eval_losses),\n",
    "}\n",
    "with open(\"results/config_a/summary.json\", \"w\") as f:\n",
    "    json.dump(config_a_results, f, indent=2)\n",
    "\n",
    "print(\"\\nLogs saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13ffed",
   "metadata": {},
   "source": [
    "### Quick Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c3ac18-d9d2-4f47-83e7-e8540c7bed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated policy:\n",
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"s3:GetObject\",\n",
      "        \"s3:ListBucket\"\n",
      "      ],\n",
      "      \"Resource\": [\n",
      "        \"arn:aws:s3:::customer-data\",\n",
      "        \"arn:aws:s3:::customer-data/*\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"logs:CreateLogGroup\",\n",
      "        \"logs:CreateLogStream\",\n",
      "        \"logs:PutLogEvents\"\n",
      "      ],\n",
      "      \"Resource\": \"*\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "‚úÖ Valid JSON!\n"
     ]
    }
   ],
   "source": [
    "# Quick inference test\n",
    "prompt = \"### Instruction:\\nAllow read-only access to S3 bucket named customer-data and write logs to CloudWatch\\n\\n### Response:\\n\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "generated_policy = response.split(\"### Response:\\n\")[-1].strip()\n",
    "\n",
    "print(\"Generated policy:\")\n",
    "print(generated_policy)\n",
    "\n",
    "# Validate JSON\n",
    "try:\n",
    "    policy = json.loads(generated_policy)\n",
    "    print(\"\\n‚úÖ Valid JSON!\")\n",
    "except:\n",
    "    print(\"\\n‚ùå Invalid JSON ‚Äî model may need more training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ca189",
   "metadata": {},
   "source": [
    "### Additional ConfigurationsWe trained 3 additional configurations to compare hyperparameter choices:\n",
    "\n",
    "| Config | Learning Rate | LoRA Rank | LoRA Alpha | Epochs | Purpose |\n",
    "|--------|--------------|-----------|------------|--------|---------|\n",
    "| **A** | 2e-4 | 16 | 32 | 3 | Balanced baseline |\n",
    "| **B** | 1e-4 | 32 | 64 | 3 | Lower LR, higher capacity |\n",
    "| **C** | 5e-4 | 16 | 32 | 5 | Aggressive LR, more epochs |\n",
    "| **D** | 2e-4 | 8 | 16 | 3 | Minimal capacity |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54ffa6",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482d952c-6b55-4d03-99b5-e3a30bf4ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HYPERPARAMETER COMPARISON ===\n",
      "Config       LR       LoRA r   Epochs   Train Loss     Best Eval Loss\n",
      "----------------------------------------------------------------\n",
      "config_a     2e-4     16       3        0.1522         0.3019        \n",
      "config_b     1e-4     32       3        0.1584         0.3025        \n",
      "config_c     5e-4     16       5        0.0481         0.3207        \n",
      "config_d     2e-4     8        3        0.1887         0.3114        \n",
      "\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "config_details = {\n",
    "    \"config_a\": {\"lr\": \"2e-4\", \"lora_r\": 16, \"lora_alpha\": 32, \"epochs\": 3},\n",
    "    \"config_b\": {\"lr\": \"1e-4\", \"lora_r\": 32, \"lora_alpha\": 64, \"epochs\": 3},\n",
    "    \"config_c\": {\"lr\": \"5e-4\", \"lora_r\": 16, \"lora_alpha\": 32, \"epochs\": 5},\n",
    "    \"config_d\": {\"lr\": \"2e-4\", \"lora_r\": 8, \"lora_alpha\": 16, \"epochs\": 3},\n",
    "}\n",
    "\n",
    "all_configs = {}\n",
    "for config_name in [\"config_a\", \"config_b\", \"config_c\", \"config_d\"]:\n",
    "    log_path = f\"results/{config_name}/training_logs.json\"\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path) as f:\n",
    "            logs = json.load(f)\n",
    "        eval_losses = [l[\"eval_loss\"] for l in logs if \"eval_loss\" in l]\n",
    "        train_losses = [l[\"loss\"] for l in logs if \"loss\" in l and \"eval_loss\" not in l]\n",
    "        all_configs[config_name] = {\n",
    "            **config_details[config_name],\n",
    "            \"best_eval_loss\": min(eval_losses) if eval_losses else None,\n",
    "            \"final_train_loss\": train_losses[-1] if train_losses else None,\n",
    "        }\n",
    "\n",
    "print(\"=== HYPERPARAMETER COMPARISON ===\")\n",
    "print(f\"{'Config':<12} {'LR':<8} {'LoRA r':<8} {'Epochs':<8} {'Train Loss':<14} {'Best Eval Loss':<14}\")\n",
    "print(\"-\" * 64)\n",
    "for name, m in all_configs.items():\n",
    "    print(f\"{name:<12} {m['lr']:<8} {m['lora_r']:<8} {m['epochs']:<8} {m['final_train_loss']:<14.4f} {m['best_eval_loss']:<14.4f}\")\n",
    "\n",
    "with open(\"results/hp_comparison.json\", \"w\") as f:\n",
    "    json.dump(all_configs, f, indent=2)\n",
    "print(\"\\nSaved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1aa99",
   "metadata": {},
   "source": [
    "## 9. Baseline vs Fine-Tuned ComparisonWe evaluate three approaches on the same 151 test examples:\n",
    "1. **Zero-shot**: Base Mistral-7B with no examples\n",
    "2. **Few-shot**: Base Mistral-7B with 3 in-context examples\n",
    "3. **Fine-tuned**: Our best model (Config A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a35c31-0955-4bad-bed5-371d0e33b681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 151 examples\n",
      "Functions ready!\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "with open(\"iam-finetuning/dataset/processed/test.jsonl\") as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "print(f\"Test set: {len(test_data)} examples\")\n",
    "\n",
    "def extract_instruction_and_expected(item):\n",
    "    text = item[\"text\"]\n",
    "    instruction = text.split(\"### Instruction:\\n\")[1].split(\"\\n\\n### Response:\")[0]\n",
    "    expected = text.split(\"### Response:\\n\")[1]\n",
    "    return instruction, expected\n",
    "\n",
    "def generate_fast(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1500).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, max_new_tokens=256, temperature=0.1, do_sample=True,\n",
    "            top_p=0.9, repetition_penalty=1.1, pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Response:\\n\")[-1].strip()\n",
    "\n",
    "few_shot_examples = \"\"\"### Instruction:\n",
    "Allow read-only access to S3 bucket named my-data\n",
    "\n",
    "### Response:\n",
    "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"s3:GetObject\",\"s3:ListBucket\"],\"Resource\":[\"arn:aws:s3:::my-data\",\"arn:aws:s3:::my-data/*\"]}]}\n",
    "\n",
    "### Instruction:\n",
    "Allow a user to start and stop EC2 instances\n",
    "\n",
    "### Response:\n",
    "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ec2:StartInstances\",\"ec2:StopInstances\",\"ec2:DescribeInstances\"],\"Resource\":\"*\"}]}\n",
    "\n",
    "### Instruction:\n",
    "Allow writing logs to CloudWatch\n",
    "\n",
    "### Response:\n",
    "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"],\"Resource\":\"*\"}]}\n",
    "\n",
    "\"\"\"\n",
    "print(\"Functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64900b8-77e3-4531-8ab9-94188760d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Metric                            Zero-Shot     Few-Shot   Fine-Tuned\n",
      "===========================================================================\n",
      "JSON Valid Rate (%)                    0.7%         2.0%        60.3%\n",
      "JSON Extracted Rate (%)               79.5%         7.3%        60.3%\n",
      "Schema Valid Rate (%)                 78.8%         7.3%        60.3%\n",
      "Service Accuracy (%)                  28.7%         0.0%        52.0%\n",
      "Effect Accuracy (%)                   98.3%       100.0%        95.6%\n",
      "===========================================================================\n",
      "\n",
      "Schema Valid Rate by Complexity:\n",
      "Complexity      Zero-Shot     Few-Shot   Fine-Tuned\n",
      "------------------------------------------------\n",
      "simple        33/42 (79%)    3/42 (7%)  32/42 (76%)\n",
      "medium        34/39 (87%)   5/39 (13%)  26/39 (67%)\n",
      "complex       52/70 (74%)    3/70 (4%)  33/70 (47%)\n",
      "\n",
      "Metrics saved!\n"
     ]
    }
   ],
   "source": [
    "metrics_zero = evaluate_results(zero_shot, \"Zero-Shot\")\n",
    "metrics_few = evaluate_results(few_shot, \"Few-Shot\")\n",
    "metrics_ft = evaluate_results(finetuned, \"Fine-Tuned\")\n",
    "\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Metric':<30} {'Zero-Shot':>12} {'Few-Shot':>12} {'Fine-Tuned':>12}\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'JSON Valid Rate (%)':<30} {metrics_zero['json_valid_rate']:>11.1f}% {metrics_few['json_valid_rate']:>11.1f}% {metrics_ft['json_valid_rate']:>11.1f}%\")\n",
    "print(f\"{'JSON Extracted Rate (%)':<30} {metrics_zero['json_extracted_rate']:>11.1f}% {metrics_few['json_extracted_rate']:>11.1f}% {metrics_ft['json_extracted_rate']:>11.1f}%\")\n",
    "print(f\"{'Schema Valid Rate (%)':<30} {metrics_zero['schema_valid_rate']:>11.1f}% {metrics_few['schema_valid_rate']:>11.1f}% {metrics_ft['schema_valid_rate']:>11.1f}%\")\n",
    "print(f\"{'Service Accuracy (%)':<30} {metrics_zero['service_accuracy']:>11.1f}% {metrics_few['service_accuracy']:>11.1f}% {metrics_ft['service_accuracy']:>11.1f}%\")\n",
    "print(f\"{'Effect Accuracy (%)':<30} {metrics_zero['effect_accuracy']:>11.1f}% {metrics_few['effect_accuracy']:>11.1f}% {metrics_ft['effect_accuracy']:>11.1f}%\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(\"\\nSchema Valid Rate by Complexity:\")\n",
    "print(f\"{'Complexity':<12} {'Zero-Shot':>12} {'Few-Shot':>12} {'Fine-Tuned':>12}\")\n",
    "print(\"-\" * 48)\n",
    "for comp in [\"simple\", \"medium\", \"complex\"]:\n",
    "    def rate(m, c):\n",
    "        total = m[\"by_complexity\"][c][\"total\"]\n",
    "        valid = m[\"by_complexity\"][c][\"schema_valid\"]\n",
    "        return f\"{valid}/{total} ({valid/total*100:.0f}%)\" if total > 0 else \"N/A\"\n",
    "    print(f\"{comp:<12} {rate(metrics_zero, comp):>12} {rate(metrics_few, comp):>12} {rate(metrics_ft, comp):>12}\")\n",
    "\n",
    "with open(\"results/evaluation_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"zero_shot\": {k: v for k, v in metrics_zero.items() if k != \"by_complexity\"},\n",
    "        \"few_shot\": {k: v for k, v in metrics_few.items() if k != \"by_complexity\"},\n",
    "        \"finetuned\": {k: v for k, v in metrics_ft.items() if k != \"by_complexity\"},\n",
    "    }, f, indent=2, default=str)\n",
    "print(\"\\nMetrics saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7fb1d2",
   "metadata": {},
   "source": [
    "## 10. Evaluation Metrics\n",
    "We measure five key metrics:-\n",
    "\n",
    "**JSON Valid Rate**: % of outputs that are directly parseable as valid JSON- \n",
    "\n",
    "**Schema Valid Rate**: % with correct IAM structure (Version, Statement, Effect, Action, Resource)- \n",
    "\n",
    "**Service Accuracy**: Jaccard similarity of AWS services between generated and expected policies- \n",
    "\n",
    "**Effect Accuracy**: Whether Allow/Deny effects match the expected policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b0d75e-1e77-43f9-b054-2060133045a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot: 151, Few-shot: 151, Fine-tuned: 151\n",
      "Evaluation functions ready!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"results/zero_shot_results.json\") as f:\n",
    "    zero_shot = json.load(f)\n",
    "with open(\"results/few_shot_results.json\") as f:\n",
    "    few_shot = json.load(f)\n",
    "with open(\"results/finetuned_results.json\") as f:\n",
    "    finetuned = json.load(f)\n",
    "\n",
    "print(f\"Zero-shot: {len(zero_shot)}, Few-shot: {len(few_shot)}, Fine-tuned: {len(finetuned)}\")\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    try:\n",
    "        return json.loads(text), True\n",
    "    except:\n",
    "        pass\n",
    "    matches = re.findall(r'\\{[\\s\\S]*\\}', text)\n",
    "    for match in matches:\n",
    "        try:\n",
    "            return json.loads(match), True\n",
    "        except:\n",
    "            continue\n",
    "    return None, False\n",
    "\n",
    "def check_policy_schema(policy):\n",
    "    errors = []\n",
    "    if not isinstance(policy, dict):\n",
    "        return False, [\"Not a JSON object\"]\n",
    "    if \"Version\" not in policy:\n",
    "        errors.append(\"missing_version\")\n",
    "    if \"Statement\" not in policy:\n",
    "        return False, [\"missing_statement\"]\n",
    "    statements = policy[\"Statement\"]\n",
    "    if isinstance(statements, dict):\n",
    "        statements = [statements]\n",
    "    if not isinstance(statements, list) or len(statements) == 0:\n",
    "        return False, [\"empty_statement\"]\n",
    "    for i, stmt in enumerate(statements):\n",
    "        if \"Effect\" not in stmt:\n",
    "            errors.append(\"missing_effect\")\n",
    "        elif stmt[\"Effect\"] not in [\"Allow\", \"Deny\"]:\n",
    "            errors.append(\"invalid_effect\")\n",
    "        if \"Action\" not in stmt and \"NotAction\" not in stmt:\n",
    "            errors.append(\"missing_action\")\n",
    "        if \"Resource\" not in stmt and \"NotResource\" not in stmt:\n",
    "            errors.append(\"missing_resource\")\n",
    "    return len(errors) == 0, errors\n",
    "\n",
    "def extract_services(policy):\n",
    "    services = set()\n",
    "    if not isinstance(policy, dict):\n",
    "        return services\n",
    "    statements = policy.get(\"Statement\", [])\n",
    "    if isinstance(statements, dict):\n",
    "        statements = [statements]\n",
    "    for stmt in statements:\n",
    "        for key in [\"Action\", \"NotAction\"]:\n",
    "            actions = stmt.get(key, [])\n",
    "            if isinstance(actions, str):\n",
    "                actions = [actions]\n",
    "            for action in actions:\n",
    "                if \":\" in action:\n",
    "                    services.add(action.split(\":\")[0].lower())\n",
    "    return services\n",
    "\n",
    "def compute_service_accuracy(expected_json, generated_json):\n",
    "    expected_services = extract_services(expected_json)\n",
    "    generated_services = extract_services(generated_json)\n",
    "    if not expected_services:\n",
    "        return 1.0 if not generated_services else 0.0\n",
    "    if not generated_services:\n",
    "        return 0.0\n",
    "    intersection = expected_services & generated_services\n",
    "    union = expected_services | generated_services\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def compute_effect_accuracy(expected_json, generated_json):\n",
    "    def get_effects(policy):\n",
    "        effects = set()\n",
    "        stmts = policy.get(\"Statement\", [])\n",
    "        if isinstance(stmts, dict):\n",
    "            stmts = [stmts]\n",
    "        for s in stmts:\n",
    "            effects.add(s.get(\"Effect\", \"\"))\n",
    "        return effects\n",
    "    return 1.0 if get_effects(expected_json) == get_effects(generated_json) else 0.0\n",
    "\n",
    "def evaluate_results(results, label):\n",
    "    metrics = {\n",
    "        \"label\": label, \"total\": len(results),\n",
    "        \"json_valid\": 0, \"json_extracted\": 0, \"schema_valid\": 0,\n",
    "        \"service_accuracy_sum\": 0, \"effect_accuracy_sum\": 0,\n",
    "        \"by_complexity\": {\n",
    "            \"simple\": {\"total\": 0, \"json_valid\": 0, \"schema_valid\": 0},\n",
    "            \"medium\": {\"total\": 0, \"json_valid\": 0, \"schema_valid\": 0},\n",
    "            \"complex\": {\"total\": 0, \"json_valid\": 0, \"schema_valid\": 0}\n",
    "        },\n",
    "    }\n",
    "    for item in results:\n",
    "        generated = item[\"generated\"]\n",
    "        expected = item[\"expected\"]\n",
    "        complexity = item.get(\"complexity\", \"medium\")\n",
    "        metrics[\"by_complexity\"][complexity][\"total\"] += 1\n",
    "\n",
    "        gen_json, extracted = extract_json_from_text(generated)\n",
    "        exp_json, _ = extract_json_from_text(expected)\n",
    "\n",
    "        if validate_json(generated):\n",
    "            metrics[\"json_valid\"] += 1\n",
    "        if extracted:\n",
    "            metrics[\"json_extracted\"] += 1\n",
    "            metrics[\"by_complexity\"][complexity][\"json_valid\"] += 1\n",
    "            schema_ok, _ = check_policy_schema(gen_json)\n",
    "            if schema_ok:\n",
    "                metrics[\"schema_valid\"] += 1\n",
    "                metrics[\"by_complexity\"][complexity][\"schema_valid\"] += 1\n",
    "            if exp_json:\n",
    "                metrics[\"service_accuracy_sum\"] += compute_service_accuracy(exp_json, gen_json)\n",
    "                metrics[\"effect_accuracy_sum\"] += compute_effect_accuracy(exp_json, gen_json)\n",
    "\n",
    "    n = metrics[\"total\"]\n",
    "    n_ext = metrics[\"json_extracted\"]\n",
    "    metrics[\"json_valid_rate\"] = metrics[\"json_valid\"] / n * 100\n",
    "    metrics[\"json_extracted_rate\"] = metrics[\"json_extracted\"] / n * 100\n",
    "    metrics[\"schema_valid_rate\"] = metrics[\"schema_valid\"] / n * 100\n",
    "    metrics[\"service_accuracy\"] = metrics[\"service_accuracy_sum\"] / n_ext * 100 if n_ext > 0 else 0\n",
    "    metrics[\"effect_accuracy\"] = metrics[\"effect_accuracy_sum\"] / n_ext * 100 if n_ext > 0 else 0\n",
    "    return metrics\n",
    "\n",
    "print(\"Evaluation functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01d1f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Metric                            Zero-Shot     Few-Shot   Fine-Tuned\n",
      "===========================================================================\n",
      "JSON Valid Rate (%)                    0.7%         2.0%        60.3%\n",
      "JSON Extracted Rate (%)               79.5%         7.3%        60.3%\n",
      "Schema Valid Rate (%)                 78.8%         7.3%        60.3%\n",
      "Service Accuracy (%)                  28.7%         0.0%        52.0%\n",
      "Effect Accuracy (%)                   98.3%       100.0%        95.6%\n",
      "===========================================================================\n",
      "\n",
      "Schema Valid Rate by Complexity:\n",
      "Complexity      Zero-Shot     Few-Shot   Fine-Tuned\n",
      "------------------------------------------------\n",
      "simple        33/42 (79%)    3/42 (7%)  32/42 (76%)\n",
      "medium        34/39 (87%)   5/39 (13%)  26/39 (67%)\n",
      "complex       52/70 (74%)    3/70 (4%)  33/70 (47%)\n",
      "\n",
      "Metrics saved!\n"
     ]
    }
   ],
   "source": [
    "metrics_zero = evaluate_results(zero_shot, \"Zero-Shot\")\n",
    "metrics_few = evaluate_results(few_shot, \"Few-Shot\")\n",
    "metrics_ft = evaluate_results(finetuned, \"Fine-Tuned\")\n",
    "\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Metric':<30} {'Zero-Shot':>12} {'Few-Shot':>12} {'Fine-Tuned':>12}\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'JSON Valid Rate (%)':<30} {metrics_zero['json_valid_rate']:>11.1f}% {metrics_few['json_valid_rate']:>11.1f}% {metrics_ft['json_valid_rate']:>11.1f}%\")\n",
    "print(f\"{'JSON Extracted Rate (%)':<30} {metrics_zero['json_extracted_rate']:>11.1f}% {metrics_few['json_extracted_rate']:>11.1f}% {metrics_ft['json_extracted_rate']:>11.1f}%\")\n",
    "print(f\"{'Schema Valid Rate (%)':<30} {metrics_zero['schema_valid_rate']:>11.1f}% {metrics_few['schema_valid_rate']:>11.1f}% {metrics_ft['schema_valid_rate']:>11.1f}%\")\n",
    "print(f\"{'Service Accuracy (%)':<30} {metrics_zero['service_accuracy']:>11.1f}% {metrics_few['service_accuracy']:>11.1f}% {metrics_ft['service_accuracy']:>11.1f}%\")\n",
    "print(f\"{'Effect Accuracy (%)':<30} {metrics_zero['effect_accuracy']:>11.1f}% {metrics_few['effect_accuracy']:>11.1f}% {metrics_ft['effect_accuracy']:>11.1f}%\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(\"\\nSchema Valid Rate by Complexity:\")\n",
    "print(f\"{'Complexity':<12} {'Zero-Shot':>12} {'Few-Shot':>12} {'Fine-Tuned':>12}\")\n",
    "print(\"-\" * 48)\n",
    "for comp in [\"simple\", \"medium\", \"complex\"]:\n",
    "    def rate(m, c):\n",
    "        total = m[\"by_complexity\"][c][\"total\"]\n",
    "        valid = m[\"by_complexity\"][c][\"schema_valid\"]\n",
    "        return f\"{valid}/{total} ({valid/total*100:.0f}%)\" if total > 0 else \"N/A\"\n",
    "    print(f\"{comp:<12} {rate(metrics_zero, comp):>12} {rate(metrics_few, comp):>12} {rate(metrics_ft, comp):>12}\")\n",
    "\n",
    "with open(\"results/evaluation_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"zero_shot\": {k: v for k, v in metrics_zero.items() if k != \"by_complexity\"},\n",
    "        \"few_shot\": {k: v for k, v in metrics_few.items() if k != \"by_complexity\"},\n",
    "        \"finetuned\": {k: v for k, v in metrics_ft.items() if k != \"by_complexity\"},\n",
    "    }, f, indent=2, default=str)\n",
    "print(\"\\nMetrics saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d3ba7",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c44ab78-b3da-4256-817e-967caeb9136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charts saved to results/evaluation_charts.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Chart 1: Main metrics\n",
    "metrics_names = [\"JSON Valid\\nRate\", \"Schema Valid\\nRate\", \"Service\\nAccuracy\", \"Effect\\nAccuracy\"]\n",
    "zero_vals = [metrics_zero[\"json_valid_rate\"], metrics_zero[\"schema_valid_rate\"], metrics_zero[\"service_accuracy\"], metrics_zero[\"effect_accuracy\"]]\n",
    "few_vals = [metrics_few[\"json_valid_rate\"], metrics_few[\"schema_valid_rate\"], metrics_few[\"service_accuracy\"], metrics_few[\"effect_accuracy\"]]\n",
    "ft_vals = [metrics_ft[\"json_valid_rate\"], metrics_ft[\"schema_valid_rate\"], metrics_ft[\"service_accuracy\"], metrics_ft[\"effect_accuracy\"]]\n",
    "\n",
    "x = range(len(metrics_names))\n",
    "width = 0.25\n",
    "axes[0].bar([i - width for i in x], zero_vals, width, label=\"Zero-Shot\", color=\"#e74c3c\")\n",
    "axes[0].bar(x, few_vals, width, label=\"Few-Shot\", color=\"#f39c12\")\n",
    "axes[0].bar([i + width for i in x], ft_vals, width, label=\"Fine-Tuned\", color=\"#2ecc71\")\n",
    "axes[0].set_ylabel(\"Percentage (%)\")\n",
    "axes[0].set_title(\"Model Comparison: Key Metrics\")\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_names)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 105)\n",
    "\n",
    "# Chart 2: By complexity\n",
    "complexities = [\"simple\", \"medium\", \"complex\"]\n",
    "for idx, (metrics, label, color) in enumerate([\n",
    "    (metrics_zero, \"Zero-Shot\", \"#e74c3c\"),\n",
    "    (metrics_few, \"Few-Shot\", \"#f39c12\"),\n",
    "    (metrics_ft, \"Fine-Tuned\", \"#2ecc71\")\n",
    "]):\n",
    "    rates = []\n",
    "    for comp in complexities:\n",
    "        total = metrics[\"by_complexity\"][comp][\"total\"]\n",
    "        valid = metrics[\"by_complexity\"][comp][\"schema_valid\"]\n",
    "        rates.append(valid / total * 100 if total > 0 else 0)\n",
    "    axes[1].bar([i + idx * 0.25 for i in range(3)], rates, 0.25, label=label, color=color)\n",
    "axes[1].set_ylabel(\"Schema Valid Rate (%)\")\n",
    "axes[1].set_title(\"Schema Validity by Complexity\")\n",
    "axes[1].set_xticks([i + 0.25 for i in range(3)])\n",
    "axes[1].set_xticklabels(complexities)\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 105)\n",
    "\n",
    "# Chart 3: Training loss curves\n",
    "with open(\"results/config_a/training_logs.json\") as f:\n",
    "    logs_a = json.load(f)\n",
    "train_steps = [l[\"step\"] for l in logs_a if \"loss\" in l and \"eval_loss\" not in l]\n",
    "train_losses = [l[\"loss\"] for l in logs_a if \"loss\" in l and \"eval_loss\" not in l]\n",
    "eval_steps = [l[\"step\"] for l in logs_a if \"eval_loss\" in l]\n",
    "eval_losses = [l[\"eval_loss\"] for l in logs_a if \"eval_loss\" in l]\n",
    "axes[2].plot(train_steps, train_losses, label=\"Train Loss\", color=\"#3498db\", linewidth=2)\n",
    "axes[2].plot(eval_steps, eval_losses, label=\"Eval Loss\", color=\"#e74c3c\", linewidth=2, marker=\"o\")\n",
    "axes[2].set_xlabel(\"Steps\")\n",
    "axes[2].set_ylabel(\"Loss\")\n",
    "axes[2].set_title(\"Config A: Training & Validation Loss\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/evaluation_charts.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(\"Charts saved to results/evaluation_charts.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5280f3-f289-4316-8621-4eb84402ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP chart saved!\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "with open(\"results/hp_comparison.json\") as f:\n",
    "    hp_data = json.load(f)\n",
    "\n",
    "configs = list(hp_data.keys())\n",
    "train_losses = [hp_data[c][\"final_train_loss\"] for c in configs]\n",
    "eval_losses = [hp_data[c][\"best_eval_loss\"] for c in configs]\n",
    "\n",
    "x = range(len(configs))\n",
    "width = 0.35\n",
    "ax.bar([i - width/2 for i in x], train_losses, width, label=\"Final Train Loss\", color=\"#3498db\")\n",
    "ax.bar([i + width/2 for i in x], eval_losses, width, label=\"Best Eval Loss\", color=\"#e74c3c\")\n",
    "\n",
    "labels = [f\"{c}\\nLR={hp_data[c]['lr']}, r={hp_data[c]['lora_r']}\" for c in configs]\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Hyperparameter Configuration Comparison\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/hp_comparison_chart.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(\"HP chart saved!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1029b57",
   "metadata": {},
   "source": [
    "## 12. Error AnalysisDetailed analysis of the fine-tuned model's failures to identify patterns and inform improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef338fba-be5c-41c3-ac00-f213cf827f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ERROR ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Fine-Tuned Model Error Breakdown (151 test examples):\n",
      "  ‚úÖ Correct:           44 (29.1%)\n",
      "  ‚ùå No JSON output:    60 (39.7%)\n",
      "  ‚ùå Invalid schema:     0 (0.0%)\n",
      "  ‚ùå Wrong services:    43 (28.5%)\n",
      "  ‚ùå Wrong effect:       4 (2.6%)\n",
      "\n",
      "======================================================================\n",
      "SPECIFIC FAILURE EXAMPLES\n",
      "======================================================================\n",
      "\n",
      "--- Example 1: NO JSON (complexity: complex) ---\n",
      "Instruction: Provide an IAM policy for Access Analyzer Service Role Policy\n",
      "Generated:   {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowAccessAnalyzerToDescribeResources\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"access-analyzer:Describe*\",\n",
      "        \"acm-\n",
      "Expected:    {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AccessAnalyzerServiceRolePolicy\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"dynamodb:GetResourcePolicy\",\n",
      "        \"dynamodb:L\n",
      "\n",
      "--- Example 2: NO JSON (complexity: medium) ---\n",
      "Instruction: Provide an IAM policy for AWS Control Tower Cloud Trail Role Policy\n",
      "Generated:   {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowControlTowerActions\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"controltower:*\"\n",
      "      ],\n",
      "      \"Resource\": \"*\"\n",
      "    },\n",
      " \n",
      "Expected:    {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": \"logs:CreateLogStream\",\n",
      "      \"Resource\": \"arn:aws:logs:*:*:log-group:aws-controltower/CloudTrailLogs*:*\"\n",
      " \n",
      "\n",
      "--- Example 3: WRONG SERVICES (complexity: complex) ---\n",
      "Instruction: Provide an IAM policy for AWSWAF Full Access\n",
      "Generated:   {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"waf:*\",\n",
      "        \"waf-regional:*\",\n",
      "        \"cloudfront:ListDistributions\",\n",
      "        \"elasticloadba\n",
      "Expected:    {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowUseOfAWSWAFClassic\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"waf:*\",\n",
      "        \"waf-regional:*\"\n",
      "      ],\n",
      "      \"Resourc\n",
      "\n",
      "--- Example 4: WRONG SERVICES (complexity: medium) ---\n",
      "Instruction: Provide an IAM policy for IVS Full Access\n",
      "Generated:   {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"ivs:*\"\n",
      "      ],\n",
      "      \"Resource\": \"*\"\n",
      "    },\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "  \n",
      "Expected:    {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"IVSFullAccess\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"ivs:*\",\n",
      "        \"ivschat:*\"\n",
      "      ],\n",
      "      \"Resource\": \"*\"\n",
      "    }\n",
      " \n",
      "\n",
      "--- Example 5: WRONG EFFECT (complexity: complex) ---\n",
      "Instruction: Provide an IAM policy for Amazon Inspector2Agentless Service Role Policy\n",
      "Generated:   {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowInspectorActions\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"inspector2:SendMetricsForInspector2\",\n",
      "        \"inspector2:\n",
      "Expected:    {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"InstanceIdentification\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"ec2:DescribeInstances\",\n",
      "        \"ec2:DescribeVolumes\",\n",
      "  \n",
      "\n",
      "--- Example 6: WRONG EFFECT (complexity: medium) ---\n",
      "Instruction: Provide an IAM policy for Amazon Connect Read Only Access\n",
      "Generated:   {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"connect:Get*\",\n",
      "        \"connect:List*\"\n",
      "      ],\n",
      "      \"Resource\": \"*\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Expected:    {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowConnectReadOnly\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"connect:Get*\",\n",
      "        \"connect:Describe*\",\n",
      "        \"connec\n",
      "\n",
      "======================================================================\n",
      "ERROR PATTERNS BY COMPLEXITY\n",
      "======================================================================\n",
      "  simple: 32/42 correct (76.2%)\n",
      "  medium: 26/39 correct (66.7%)\n",
      "  complex: 33/70 correct (47.1%)\n",
      "\n",
      "======================================================================\n",
      "SUGGESTED IMPROVEMENTS\n",
      "======================================================================\n",
      "  1. Add constrained/guided decoding to enforce JSON output structure\n",
      "  2. Post-processing validation layer to auto-correct common schema issues\n",
      "  3. Augment training data with more diverse service combinations\n",
      "  4. Add more Deny/mixed Allow-Deny examples\n",
      "  5. RAG with AWS action catalog to prevent hallucinated action names\n",
      "  6. Increase dataset to 5,000+ examples focusing on complex policies\n",
      "  7. Try DPO/RLHF to improve policy correctness beyond SFT\n",
      "\n",
      "Error analysis saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "error_categories = {\n",
    "    \"no_json\": [], \"invalid_schema\": [], \"wrong_services\": [],\n",
    "    \"wrong_effect\": [], \"correct\": [],\n",
    "}\n",
    "\n",
    "for item in finetuned:\n",
    "    gen_json, extracted = extract_json_from_text(item[\"generated\"])\n",
    "    exp_json, _ = extract_json_from_text(item[\"expected\"])\n",
    "    \n",
    "    if not extracted:\n",
    "        error_categories[\"no_json\"].append(item)\n",
    "        continue\n",
    "    schema_ok, errors = check_policy_schema(gen_json)\n",
    "    if not schema_ok:\n",
    "        error_categories[\"invalid_schema\"].append(item)\n",
    "        continue\n",
    "    if exp_json:\n",
    "        svc_acc = compute_service_accuracy(exp_json, gen_json)\n",
    "        eff_acc = compute_effect_accuracy(exp_json, gen_json)\n",
    "        if eff_acc < 1.0:\n",
    "            error_categories[\"wrong_effect\"].append(item)\n",
    "        elif svc_acc < 0.5:\n",
    "            error_categories[\"wrong_services\"].append(item)\n",
    "        else:\n",
    "            error_categories[\"correct\"].append(item)\n",
    "\n",
    "total = len(finetuned)\n",
    "print(f\"\\nFine-Tuned Model Error Breakdown ({total} test examples):\")\n",
    "print(f\"  ‚úÖ Correct:         {len(error_categories['correct']):>4} ({len(error_categories['correct'])/total*100:.1f}%)\")\n",
    "print(f\"  ‚ùå No JSON output:  {len(error_categories['no_json']):>4} ({len(error_categories['no_json'])/total*100:.1f}%)\")\n",
    "print(f\"  ‚ùå Invalid schema:  {len(error_categories['invalid_schema']):>4} ({len(error_categories['invalid_schema'])/total*100:.1f}%)\")\n",
    "print(f\"  ‚ùå Wrong services:  {len(error_categories['wrong_services']):>4} ({len(error_categories['wrong_services'])/total*100:.1f}%)\")\n",
    "print(f\"  ‚ùå Wrong effect:    {len(error_categories['wrong_effect']):>4} ({len(error_categories['wrong_effect'])/total*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SPECIFIC FAILURE EXAMPLES\")\n",
    "print(\"=\" * 70)\n",
    "example_count = 0\n",
    "for category, label in [(\"no_json\",\"NO JSON\"), (\"invalid_schema\",\"BAD SCHEMA\"), (\"wrong_services\",\"WRONG SERVICES\"), (\"wrong_effect\",\"WRONG EFFECT\")]:\n",
    "    for item in error_categories[category][:2]:\n",
    "        if example_count >= 8: break\n",
    "        example_count += 1\n",
    "        print(f\"\\n--- Example {example_count}: {label} (complexity: {item.get('complexity','?')}) ---\")\n",
    "        print(f\"Instruction: {item['instruction'][:150]}\")\n",
    "        print(f\"Generated:   {item['generated'][:200]}\")\n",
    "        print(f\"Expected:    {item['expected'][:200]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ERROR PATTERNS BY COMPLEXITY\")\n",
    "print(\"=\" * 70)\n",
    "for comp in [\"simple\", \"medium\", \"complex\"]:\n",
    "    comp_items = [item for item in finetuned if item.get(\"complexity\") == comp]\n",
    "    comp_correct = sum(1 for item in comp_items if extract_json_from_text(item[\"generated\"])[1] and check_policy_schema(extract_json_from_text(item[\"generated\"])[0])[0])\n",
    "    print(f\"  {comp}: {comp_correct}/{len(comp_items)} correct ({comp_correct/len(comp_items)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUGGESTED IMPROVEMENTS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  1. Add constrained/guided decoding to enforce JSON output structure\")\n",
    "print(\"  2. Post-processing validation layer to auto-correct common schema issues\")\n",
    "print(\"  3. Augment training data with more diverse service combinations\")\n",
    "print(\"  4. Add more Deny/mixed Allow-Deny examples\")\n",
    "print(\"  5. RAG with AWS action catalog to prevent hallucinated action names\")\n",
    "print(\"  6. Increase dataset to 5,000+ examples focusing on complex policies\")\n",
    "print(\"  7. Try DPO/RLHF to improve policy correctness beyond SFT\")\n",
    "\n",
    "with open(\"results/error_analysis.json\", \"w\") as f:\n",
    "    json.dump({\"summary\": {cat: len(items) for cat, items in error_categories.items()}}, f, indent=2)\n",
    "print(\"\\nError analysis saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e4d63",
   "metadata": {},
   "source": [
    "## 13. Side-by-Side Comparison Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad891ac-ac2a-426c-b9dc-063d348ee23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SIDE-BY-SIDE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "INSTRUCTION: Provide an IAM policy for AWSWAF Full Access\n",
      "COMPLEXITY: complex\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  [Zero-Shot] ‚úÖ Valid\n",
      "  ```json\n",
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"VisualEditor0\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"waf-regi...\n",
      "\n",
      "  [Few-Shot] ‚úÖ Valid\n",
      "  {\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"*\"],\"Resource\":\"*\"}]}\n",
      "\n",
      "### Instruction:\n",
      "Allow a user to create, update, delete, and ...\n",
      "\n",
      "  [Fine-Tuned] ‚úÖ Valid\n",
      "  {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"waf:*\",\n",
      "        \"waf-regional:*\",\n",
      "        \"clo...\n",
      "\n",
      "======================================================================\n",
      "INSTRUCTION: Provide an IAM policy for AWS Marketplace License Management Service Role Policy\n",
      "COMPLEXITY: medium\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  [Zero-Shot] ‚úÖ Valid\n",
      "  ```json\n",
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"license-manager:*\"\n",
      "      ],\n",
      "      \"Res...\n",
      "\n",
      "  [Few-Shot] ‚ùå No JSON\n",
      "  {\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ec2:AuthorizeSecurityGroupIngress\",\"...\n",
      "\n",
      "  [Fine-Tuned] ‚ùå No JSON\n",
      "  {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"MarketplaceLicenseManagementServiceRolePolicy\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Acti...\n",
      "\n",
      "======================================================================\n",
      "INSTRUCTION: Provide an IAM policy for AWS Backup Audit Access\n",
      "COMPLEXITY: complex\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  [Zero-Shot] ‚úÖ Valid\n",
      "  ```json\n",
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowBackupAuditAccess\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        ...\n",
      "\n",
      "  [Few-Shot] ‚ùå No JSON\n",
      "  {\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"backup:ListBackupVaults\",\"backup:ListBackups\",\"backup:ListTagsForResource\",\"backup:L...\n",
      "\n",
      "  [Fine-Tuned] ‚úÖ Valid\n",
      "  {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AWSBackupAuditAccess\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"backup:Li...\n",
      "\n",
      "======================================================================\n",
      "INSTRUCTION: Provide an IAM policy for Amazon RDS Custom Service Role Policy\n",
      "COMPLEXITY: complex\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  [Zero-Shot] ‚ùå No JSON\n",
      "  ```json\n",
      "{\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"rds-db:CreateDBCluster\",\n",
      "        \"rds-...\n",
      "\n",
      "  [Few-Shot] ‚ùå No JSON\n",
      "  {\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":...\n",
      "\n",
      "  [Fine-Tuned] ‚ùå No JSON\n",
      "  {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": [\n",
      "        \"ec2:DescribeVpcs\",\n",
      "        \"ec2:DescribeSubnet...\n",
      "\n",
      "======================================================================\n",
      "INSTRUCTION: Provide an IAM policy for Amazon Sage Maker Service Catalog Products Cloudformation Service Role Policy\n",
      "COMPLEXITY: medium\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  [Zero-Shot] ‚úÖ Valid\n",
      "  ```json\n",
      "{\n",
      "    \"Version\": \"2012-10-17\",\n",
      "    \"Statement\": [\n",
      "        {\n",
      "            \"Effect\": \"Allow\",\n",
      "            \"Action\": [\n",
      "                \"sagemaker:...\n",
      "\n",
      "  [Few-Shot] ‚ùå No JSON\n",
      "  {\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"iam:PassRole\",\"iam:ListRoles\",\"iam:ListAttachedRolePolicies\",\"iam:ListAttachedRolePo...\n",
      "\n",
      "  [Fine-Tuned] ‚úÖ Valid\n",
      "  {\n",
      "  \"Version\": \"2012-10-17\",\n",
      "  \"Statement\": [\n",
      "    {\n",
      "      \"Sid\": \"AllowCloudFormationOperationsOnAllStacks\",\n",
      "      \"Effect\": \"Allow\",\n",
      "      \"Action\": ...\n",
      "\n",
      "Comparison saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SIDE-BY-SIDE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "indices = [0, len(test_data)//4, len(test_data)//2, 3*len(test_data)//4, -1]\n",
    "for idx in indices:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"INSTRUCTION: {zero_shot[idx]['instruction'][:120]}\")\n",
    "    print(f\"COMPLEXITY: {zero_shot[idx].get('complexity', '?')}\")\n",
    "    print(\"-\"*70)\n",
    "    for label, results in [(\"Zero-Shot\", zero_shot), (\"Few-Shot\", few_shot), (\"Fine-Tuned\", finetuned)]:\n",
    "        gen_json, extracted = extract_json_from_text(results[idx][\"generated\"])\n",
    "        if extracted:\n",
    "            schema_ok, _ = check_policy_schema(gen_json)\n",
    "            status = \"‚úÖ Valid\" if schema_ok else \"‚ö†Ô∏è Bad Schema\"\n",
    "        else:\n",
    "            status = \"‚ùå No JSON\"\n",
    "        print(f\"\\n  [{label}] {status}\")\n",
    "        print(f\"  {results[idx]['generated'][:150]}...\")\n",
    "\n",
    "with open(\"results/comparison_examples.json\", \"w\") as f:\n",
    "    json.dump([{\n",
    "        \"instruction\": zero_shot[i][\"instruction\"],\n",
    "        \"expected\": zero_shot[i][\"expected\"][:300],\n",
    "        \"zero_shot\": zero_shot[i][\"generated\"][:300],\n",
    "        \"few_shot\": few_shot[i][\"generated\"][:300],\n",
    "        \"finetuned\": finetuned[i][\"generated\"][:300],\n",
    "    } for i in range(min(10, len(test_data)))], f, indent=2)\n",
    "print(\"\\nComparison saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47b704",
   "metadata": {},
   "source": [
    "## 14. Inference Pipeline\n",
    "### Gradio Demo Application Saved as `inference_app.py` ‚Äî run with `python inference_app.py` on a GPU instance.\n",
    "### Inference Pipeline ClassSaved as `inference_pipeline.py` ‚Äî import and use programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d7e9ce-1306-4549-ac6d-5f1addf5b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio app saved to inference_app.py\n",
      "To run: python inference_app.py (requires GPU)\n"
     ]
    }
   ],
   "source": [
    "# Save the Gradio app as a standalone Python file\n",
    "gradio_code = '''\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# ---- Load Model ----\n",
    "model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, quantization_config=bnb_config, device_map=\"auto\", dtype=torch.bfloat16,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"results/config_a/final_model\")\n",
    "model.eval()\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# ---- Inference Function ----\n",
    "def generate_policy(description, max_tokens=512, temperature=0.1):\n",
    "    prompt = f\"### Instruction:\\\\n{description}\\\\n\\\\n### Response:\\\\n\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, max_new_tokens=max_tokens, temperature=temperature,\n",
    "            do_sample=True, top_p=0.9, repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    policy_text = response.split(\"### Response:\\\\n\")[-1].strip()\n",
    "\n",
    "    # Validate\n",
    "    try:\n",
    "        parsed = json.loads(policy_text)\n",
    "        return json.dumps(parsed, indent=2), \"‚úÖ Valid IAM Policy\"\n",
    "    except json.JSONDecodeError:\n",
    "        return policy_text, \"‚ùå Invalid JSON - may need manual correction\"\n",
    "\n",
    "# ---- Gradio Interface ----\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_policy,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Describe the IAM policy you need\", lines=3,\n",
    "                   placeholder=\"e.g., Allow read-only access to S3 bucket named customer-data\"),\n",
    "        gr.Slider(minimum=128, maximum=1024, value=512, step=64, label=\"Max Tokens\"),\n",
    "        gr.Slider(minimum=0.0, maximum=1.0, value=0.1, step=0.05, label=\"Temperature\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Code(label=\"Generated IAM Policy\", language=\"json\"),\n",
    "        gr.Textbox(label=\"Validation Status\"),\n",
    "    ],\n",
    "    title=\"AWS IAM Policy Generator\",\n",
    "    description=\"Fine-tuned Mistral-7B model that converts natural language descriptions into valid AWS IAM policies.\",\n",
    "    examples=[\n",
    "        [\"Allow read-only access to S3 bucket named customer-data\", 512, 0.1],\n",
    "        [\"Allow a Lambda function to read from DynamoDB table users and write logs to CloudWatch\", 512, 0.1],\n",
    "        [\"Deny all S3 delete operations across all buckets\", 512, 0.1],\n",
    "        [\"Allow EC2 instances tagged with Team=backend to be started and stopped\", 512, 0.1],\n",
    "        [\"Allow assuming a cross-account role in account 987654321098\", 512, 0.1],\n",
    "    ],\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n",
    "'''\n",
    "\n",
    "with open(\"inference_app.py\", \"w\") as f:\n",
    "    f.write(gradio_code)\n",
    "\n",
    "print(\"Gradio app saved to inference_app.py\")\n",
    "print(\"To run: python inference_app.py (requires GPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09a082",
   "metadata": {},
   "source": [
    "## Results Summary\r\n",
    "\r\n",
    "### Key Findings\r\n",
    "\r\n",
    "| Metric | Zero-Shot | Few-Shot | Fine-Tuned |\r\n",
    "|--------|-----------|----------|------------|\r\n",
    "| JSON Valid Rate | 0.7% | 2.0% | **60.3%** |\r\n",
    "| Schema Valid Rate | 78.8%* | 7.3% | **60.3%** |\r\n",
    "| Service Accuracy | 28.7% | 0.0% | **52.0%** |\r\n",
    "| Effect Accuracy | 98.3% | 100.0% | **95.6%** |\r\n",
    "\r\n",
    "*Zero-shot produces JSON wrapped in markdown code blocks ‚Äî not directly parseable in production.*\r\n",
    "\r\n",
    "### Hyperparameter Results\r\n",
    "\r\n",
    "| Config | LR | LoRA r | Best Eval Loss | Notes |\r\n",
    "|--------|-----|--------|----------------|-------|\r\n",
    "| **A** ‚úÖ | 2e-4 | 16 | **0.3019** | Best overall |\r\n",
    "| B | 1e-4 | 32 | 0.3025 | Close second |\r\n",
    "| C | 5e-4 | 16 | 0.3207 | Overfits |\r\n",
    "| D | 2e-4 | 8 | 0.3114 | Underfits |\r\n",
    "\r\n",
    "### Error Analysis (Fine-Tuned Model)\r\n",
    "\r\n",
    "| Category | Count | Rate |\r\n",
    "|----------|-------|------|\r\n",
    "| ‚úÖ Correct | 44 | 29.1% |\r\n",
    "| ‚ùå Truncated output (no complete JSON) | 60 | 39.7% |\r\n",
    "| ‚ùå Wrong services | 43 | 28.5% |\r\n",
    "| ‚ùå Wrong effect | 4 | 2.6% |\r\n",
    "\r\n",
    "### Accuracy by Complexity\r\n",
    "\r\n",
    "| Complexity | Accuracy |\r\n",
    "|------------|----------|\r\n",
    "| Simple | 76.2% |\r\n",
    "| Medium | 66.7% |\r\n",
    "| Complex | 47.1% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc77294-5a44-41a4-a294-c30d45feabcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
